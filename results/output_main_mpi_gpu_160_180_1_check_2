Sender: LSF System <lsfadmin@polus-c2-ib.bmc.hpc.cs.msu.ru>
Subject: Job 1286110: <mpiexec -n 1 ./main_mpi_gpu_160_180> in cluster <MSUCluster> Done

Job <mpiexec -n 1 ./main_mpi_gpu_160_180> was submitted from host <polus-ib.bmc.hpc.cs.msu.ru> by user <edu-cmc-skmodel24-619-07> in cluster <MSUCluster> at Thu Dec 19 10:53:56 2024
Job was executed on host(s) <polus-c2-ib.bmc.hpc.cs.msu.ru>, in queue <short>, as user <edu-cmc-skmodel24-619-07> in cluster <MSUCluster> at Thu Dec 19 10:53:56 2024
</home_edu/edu-cmc-skmodel24-619/edu-cmc-skmodel24-619-07> was used as the home directory.
</home_edu/edu-cmc-skmodel24-619/edu-cmc-skmodel24-619-07> was used as the working directory.
Started at Thu Dec 19 10:53:56 2024
Terminated at Thu Dec 19 10:53:58 2024
Results reported at Thu Dec 19 10:53:58 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
mpiexec -n 1 ./main_mpi_gpu_160_180
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   0.39 sec.
    Max Memory :                                 93 MB
    Average Memory :                             62.33 MB
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                13
    Run time :                                   4 sec.
    Turnaround time :                            2 sec.

The output (if any) follows:

0 1
2 0.160338
time_AW = 0.000200
time_update_to_host_r = 0.000074
time_scalar_r_r = 0.000152
time_asycn_send = 0.000005
time_update_to_device_r = 0.000046
time_Ar = 0.000067
time_scalar_Ar_r = 0.000093
time_tau = 0.000056
time_new_w = 0.000049


PS:

Read file <error_main_mpi_gpu_160_180_1_check_2> for stderr output of this job.

