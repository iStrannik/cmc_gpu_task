Sender: LSF System <lsfadmin@polus-c3-ib.bmc.hpc.cs.msu.ru>
Subject: Job 1286075: <mpiexec -n 2 ./main_mpi_gpu_160_180> in cluster <MSUCluster> Done

Job <mpiexec -n 2 ./main_mpi_gpu_160_180> was submitted from host <polus-ib.bmc.hpc.cs.msu.ru> by user <edu-cmc-skmodel24-619-07> in cluster <MSUCluster> at Thu Dec 19 10:06:05 2024
Job was executed on host(s) <2*polus-c3-ib.bmc.hpc.cs.msu.ru>, in queue <short>, as user <edu-cmc-skmodel24-619-07> in cluster <MSUCluster> at Thu Dec 19 10:06:06 2024
</home_edu/edu-cmc-skmodel24-619/edu-cmc-skmodel24-619-07> was used as the home directory.
</home_edu/edu-cmc-skmodel24-619/edu-cmc-skmodel24-619-07> was used as the working directory.
Started at Thu Dec 19 10:06:06 2024
Terminated at Thu Dec 19 10:08:36 2024
Results reported at Thu Dec 19 10:08:36 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
mpiexec -n 2 ./main_mpi_gpu_160_180
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   300.75 sec.
    Max Memory :                                 1443 MB
    Average Memory :                             915.67 MB
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              6
    Max Threads :                                21
    Run time :                                   150 sec.
    Turnaround time :                            151 sec.

The output (if any) follows:

0 2
1 2
436649 148.769505
time_AW = 13.280702
time_update_to_host_r = 11.021204
time_scalar_r_r = 41.174089
time_asycn_send = 1.112356
time_update_to_device_r = 9.253544
time_Ar = 13.440612
time_scalar_Ar_r = 40.895323
time_tau = 5.142855
time_new_w = 11.407223


PS:

Read file <error_main_mpi_gpu_160_180_2> for stderr output of this job.

